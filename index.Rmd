---
title: "The similarity of gym music"
output:
  flexdashboard::flex_dashboard:
    orientation: columns
---

Home
===================================== 

Column {data-width=500}
-----------------------------------------------------------------------

<style type="text/css">

.overview {
   font-size: 15px;

</style>

### Overview {.overview}

```{=html}
<iframe style="border-radius:12px"
src="https://open.spotify.com/embed/track/4Uiw0Sl9yskBaC6P4DcdVD" width="100%" height="152" frameBorder="0" allowtransparency="true" allow="encrypted-media" data-external="1"></iframe>
```

<a href="https://open.spotify.com/playlist/6sCXB5zUhjzbpXnLYOMdi1?si=e8abc3f35f9844df">Link to my corpus (spotify)</a>

My corpus of songs contains my personal music playlist I listen to when I go to the gym. This is a playlist of songs that will make me lift more, unlike some other music I have listened to. For some reason I cannot get enough of the songs when I am working out but I scarcely listen to these songs when I am for example at home sitting on the couch. What makes these songs so good in the gym compared to other songs?

The playlist mainly consists of metal songs and rapsongs. I personally think metal and rap are common genres in a 'workout' playlist, along side house and dubstep. 

As this is just a corpus of ~50 songs I do not think these songs represent the genre well enough, as artists such as Deftones and Eminem are very mainstream in their genre. Furthermore, due to the small size of songs in this corpus, I do think one should take the conclusions drawn from this analysis with a grain of salt, and are for personal amusement only. I have split this playlist into the the genres: House, metal and hiphop/rap to see what these songs have in common.

Looking at the upperplot, we can see almost every song in my corpus has a high energy value. This is to be expected, as you will not listen to 'low energy' songs in the gym. In the second plot we can see the tempo over the danceability, where we can clearly see that the songs in the corpus has mostly songs with a high beats per minute (BPM). This is obviously correlated with the high energy the songs has, what was also clearly seen in the plot above. Lastly, the songs tend to be loud, with metal being a clear example.

<h2>Outliers</h2>

The outliers, (low energy, low valence) are all from the artist Kuoga. This is trap/house music. Logically speaking, this is low valence. What makes up for the low energy (according to spotify) is the drop fitting for cardio and lifting. Other outliers are the songs of Gojira, heavy metal. These songs have almost the maximum value of energy and the tempo is around 150 BPM, pretty self explanatory. One funny outlier is Awaken, low tempo and low danceability. This song has in my opinion a good chorus to make up for it.


Column {.tabset}
-----------------------------------------------------------------------

### Energy over valence
```{r}
library(tidyverse)
library(spotifyr)
library(ggplot2)
library(flexdashboard)
library(readr)
library(lubridate)
library(plotly)
library(compmus)

cm <- get_playlist_audio_features("", "0Exrs3zznekmCiCjhGZ3X9")
cm1 <- get_playlist_audio_features("", "2tO0uLN5SxReQo533Ekoo4")
cm2 <- get_playlist_audio_features("", "5aGC1K6IyQkXicMaaIA82Y")
cm3 <- get_playlist_audio_features("", "5CMf4RYXFouuTKqI6RZ8iY")

fig <- plot_ly()
fig <- fig %>%
  add_trace(
    data=cm1,
    x=~valence,
    y=~energy,
    type = "scatter",
    hoverinfo='text',
    mode = "markers",
    name='Rap',
    marker = list(color='green'),
    text= paste(
                cm1$track.name,
                "<br>",
                "Valence: ", cm1$valence,
                "<br>",
                "Energy: ", cm1$energy
    )
)

fig <- fig %>%
  add_trace(
    data=cm2,
    x=~valence,
    y=~energy,
    type = "scatter",
    hoverinfo='text',
    mode = "markers",
    name='Metal',
    marker = list(color='red'),
    text= paste(
      cm2$track.name,
      "<br>",
      "Valence: ", cm2$valence,
      "<br>",
      "Energy: ", cm2$energy
    )
)

fig <- fig %>%
  add_trace(
    data=cm3,
    x=~valence,
    y=~energy,
    type = "scatter",
    hoverinfo='text',
    mode = "markers",
    marker = list(color='blue'),
    name='House/rest',
    text= paste(
      cm3$track.name,
      "<br>",
      "Valence: ", cm3$valence,
      "<br>",
      "Energy: ", cm3$energy
    )
  )

fig
```
### Tempo over the danceability, scaling with the loudness of the song
```{r}
fig2 <- plot_ly()
fig2 <- fig2 %>%
  add_trace(
    data=cm1,
    x=~danceability,
    y=~tempo,
    type = "scatter",
    hoverinfo='text',
    mode = "markers",
    size=~loudness,
    name='Rap',
    marker = list(color='green'),
    text= paste(
      cm1$track.name,
      "<br>",
      "Danceability: ", cm1$danceability,
      "<br>",
      "Tempo: ", cm1$tempo,
      "<br>",
      "Loudness: ", cm1$loudness
    )
  )

fig2 <- fig2 %>%
  add_trace(
    data=cm2,
    x=~danceability,
    y=~tempo,
    type = "scatter",
    hoverinfo='text',
    mode = "markers",
    size=~loudness,
    name='Metal',
    marker = list(color='red'),
    text= paste(
      cm2$track.name,
      "<br>",
      "Danceability: ", cm2$danceability,
      "<br>",
      "Tempo: ", cm2$tempo,
      "<br>",
      "Loudness: ", cm2$loudness
    )
  )

fig2 <- fig2 %>%
  add_trace(
    data=cm3,
    x=~danceability,
    y=~tempo,
    type = "scatter",
    hoverinfo='text',
    mode = "markers",
    size=~loudness,
    name='House/rest',
    marker = list(color='blue'),
    text= paste(
      cm3$track.name,
      "<br>",
      "Danceability: ", cm3$danceability,
      "<br>",
      "Tempo: ", cm3$tempo,
      "<br>",
      "Loudness: ", cm3$loudness
    )
  )

fig2
```

Chromagrams
=====================================

Column {data-width=500}
-----------------------------------------------------------------------

### Chromagrams

In the chromograms we could clearly see distinction between low tempo songs and high tempo songs, Be quiet and drive has a lot of different magnitudes per second, indicating a high BPM, unlike Pray and Awaken. 

Column {.tabset}
-----------------------------------------------------------------------

### Awaken - Valerie Broussard

```{r}
awaken<-
  get_tidy_audio_analysis("3jevgr3fYdv9wYO3IDJq2a") |>
  select(segments) |>
  unnest(segments) |>
  select(start, duration, pitches)

awaken |>
  mutate(pitches = map(pitches, compmus_normalise, "euclidean")) |>
  compmus_gather_chroma() |> 
  ggplot(
    aes(
      x = start + duration / 2,
      width = duration,
      y = pitch_class,
      fill = value
    )
  ) +
  geom_tile() +
  labs(x = "Time (s)", y = NULL, fill = "Magnitude") +
  theme_minimal() +
  scale_fill_viridis_c()

```

### Pray - Kuoga, Ivy
```{r}
pray<-
  get_tidy_audio_analysis("4FrZMNz4zpTMECW6EZ3vsx") |>
  select(segments) |>
  unnest(segments) |>
  select(start, duration, pitches)

pray |>
  mutate(pitches = map(pitches, compmus_normalise, "euclidean")) |>
  compmus_gather_chroma() |> 
  ggplot(
    aes(
      x = start + duration / 2,
      width = duration,
      y = pitch_class,
      fill = value
    )
  ) +
  geom_tile() +
  labs(x = "Time (s)", y = NULL, fill = "Magnitude") +
  theme_minimal() +
  scale_fill_viridis_c()
```

### Be quiet and drive (far away) - Deftones

```{r}
deft<-
  get_tidy_audio_analysis("4Uiw0Sl9yskBaC6P4DcdVD") |>
  select(segments) |>
  unnest(segments) |>
  select(start, duration, pitches)

deft |>
  mutate(pitches = map(pitches, compmus_normalise, "euclidean")) |>
  compmus_gather_chroma() |> 
  ggplot(
    aes(
      x = start + duration / 2,
      width = duration,
      y = pitch_class,
      fill = value
    )
  ) +
  geom_tile() +
  labs(x = "Time (s)", y = NULL, fill = "Magnitude") +
  theme_minimal() +
  scale_fill_viridis_c()
```

Cepstrograms
=====================================

Column {data-width=500}
-----------------------------------------------------------------------

### Cepstrograms

The first cepstrogram, Awaken, we do not see a clear difference in the magnitudes. This is probablily due to the fact that the song is rather slow. The higher magnitudes are most likely because of the violin that is starting to play around that timeframe. This plot is made with "manhattan" normalisation and a root mean square function for readability purposes.

The second plot is of a quintessential example of a metal song, high BPM, and a lot of electric guitar. As there are no big jumps in magnitudes for this plot I have chosen a "euclidean" and mean function. 

Lastly, a house song, Quiet by Kuoga. This plot looks a bit like the first one, with clear jumps in magnitude when the house drop starts and finishes. With this plot, I used euclidean instead of manhattan as that resulted in a better plot.

Column {.tabset}
-----------------------------------------------------------------------

### Awaken

```{r}
awaken_timbre <-
  get_tidy_audio_analysis("3jevgr3fYdv9wYO3IDJq2a") |> # Change URI.
  compmus_align(bars, segments) |>                     # Change `bars`
  select(bars) |>                                      #   in all three
  unnest(bars) |>                                      #   of these lines.
  mutate(
    pitches =
      map(segments,
          compmus_summarise, pitches,
          method = "rms", norm = "manhattan"              # Change summary & norm.
      )
  ) |>
  mutate(
    timbre =
      map(segments,
          compmus_summarise, timbre,
          method = "rms", norm = "manhattan"              # Change summary & norm.
      )
  )

awaken_timbre |>
  compmus_gather_timbre() |>
  ggplot(
    aes(
      x = start + duration / 2,
      width = duration,
      y = basis,
      fill = value
    )
  ) +
  geom_tile() +
  labs(x = "Time (s)", y = NULL, fill = "Magnitude") +
  scale_fill_viridis_c() +                              
  theme_classic()
```

### Be quiet and drive (far away)

```{r}
deft_timbre <-
  get_tidy_audio_analysis("4Uiw0Sl9yskBaC6P4DcdVD") |> # Change URI.
  compmus_align(bars, segments) |>                     # Change `bars`
  select(bars) |>                                      #   in all three
  unnest(bars) |>                                      #   of these lines.
  mutate(
    pitches =
      map(segments,
          compmus_summarise, pitches,
          method = "mean", norm = "euclidean"              # Change summary & norm.
      )
  ) |>
  mutate(
    timbre =
      map(segments,
          compmus_summarise, timbre,
          method = "mean", norm = "euclidean"              # Change summary & norm.
      )
  )

deft_timbre |>
  compmus_gather_timbre() |>
  ggplot(
    aes(
      x = start + duration / 2,
      width = duration,
      y = basis,
      fill = value
    )
  ) +
  geom_tile() +
  labs(x = "Time (s)", y = NULL, fill = "Magnitude") +
  scale_fill_viridis_c() +                              
  theme_classic()
```

### Quiet - Kuoga

```{r}
q_timbre <-
  get_tidy_audio_analysis("5ouJ45sdbOh6QdzkVodn0Z") |> # Change URI.
  compmus_align(bars, segments) |>                     # Change `bars`
  select(bars) |>                                      #   in all three
  unnest(bars) |>                                      #   of these lines.
  mutate(
    pitches =
      map(segments,
          compmus_summarise, pitches,
          method = "rms", norm = "euclidean"              # Change summary & norm.
      )
  ) |>
  mutate(
    timbre =
      map(segments,
          compmus_summarise, timbre,
          method = "rms", norm = "euclidean"              # Change summary & norm.
      )
  )

q_timbre |>
  compmus_gather_timbre() |>
  ggplot(
    aes(
      x = start + duration / 2,
      width = duration,
      y = basis,
      fill = value
    )
  ) +
  geom_tile() +
  labs(x = "Time (s)", y = NULL, fill = "Magnitude") +
  scale_fill_viridis_c() +                              
  theme_classic()
```

Self-Similarity Matrices
=====================================

Column {data-width=500}
-----------------------------------------------------------------------

### Self-Similarity Matrices

Same songs again, as they're a good representation of the three main genres I have in my corpus. In "Awaken" we see a visible jump in magnitude at the end of the song. This can also be clearly heard, as all the instruments are played together. 

In "Be quiet and drive (far away)" there are three major magnitudes in the chroma SSM. This is the "iconic" part of the electric guitar of the song. (sorry I am not very knowledgable on this field, guitars... ) You could try it out yourself at timestamps 100 sec and 150 sec.

The major magnitude in "Quiet" is the part where the synthesizer starts playing at ~80 sec. Then it sort of falls of, where de second drop of the song begins.

Column {.tabset}
-----------------------------------------------------------------------

### Awaken

```{r}
library("ggpubr")
a <- awaken_timbre |>
  compmus_self_similarity(timbre, "cosine") |> 
  ggplot(
    aes(
      x = xstart + xduration / 2,
      width = xduration,
      y = ystart + yduration / 2,
      height = yduration,
      fill = d
    )
  ) +
  geom_tile() +
  coord_fixed() +
  scale_fill_viridis_c(guide = "none") +
  theme_classic() +
  labs(x = "", y = "")

b <- awaken_timbre |>
  compmus_self_similarity(pitches, "cosine") |> 
  ggplot(
    aes(
      x = xstart + xduration / 2,
      width = xduration,
      y = ystart + yduration / 2,
      height = yduration,
      fill = d
    )
  ) +
  geom_tile() +
  coord_fixed() +
  scale_fill_viridis_c(guide = "none") +
  theme_classic() +
  labs(x = "", y = "")

figure <- ggarrange(a, b,
                    labels = c("SSM (timbre)", "SSM (chroma)"),
                    ncol = 1, nrow = 2)

figure
```  

### Be quiet and drive (far away)

```{r}
c <- deft_timbre |>
  compmus_self_similarity(timbre, "cosine") |> 
  ggplot(
    aes(
      x = xstart + xduration / 2,
      width = xduration,
      y = ystart + yduration / 2,
      height = yduration,
      fill = d
    )
  ) +
  geom_tile() +
  coord_fixed() +
  scale_fill_viridis_c(guide = "none") +
  theme_classic() +
  labs(x = "", y = "")

d <- deft_timbre |>
  compmus_self_similarity(pitches, "cosine") |> 
  ggplot(
    aes(
      x = xstart + xduration / 2,
      width = xduration,
      y = ystart + yduration / 2,
      height = yduration,
      fill = d
    )
  ) +
  geom_tile() +
  coord_fixed() +
  scale_fill_viridis_c(guide = "none") +
  theme_classic() +
  labs(x = "", y = "")

figure2 <- ggarrange(c, d,
                    labels = c("SSM (timbre)", "SSM (chroma)"),
                    ncol = 1, nrow = 2)

figure2
```

### Quiet 

```{r}
c <- q_timbre |>
  compmus_self_similarity(timbre, "cosine") |> 
  ggplot(
    aes(
      x = xstart + xduration / 2,
      width = xduration,
      y = ystart + yduration / 2,
      height = yduration,
      fill = d
    )
  ) +
  geom_tile() +
  coord_fixed() +
  scale_fill_viridis_c(guide = "none") +
  theme_classic() +
  labs(x = "", y = "")

d <- q_timbre |>
  compmus_self_similarity(pitches, "cosine") |> 
  ggplot(
    aes(
      x = xstart + xduration / 2,
      width = xduration,
      y = ystart + yduration / 2,
      height = yduration,
      fill = d
    )
  ) +
  geom_tile() +
  coord_fixed() +
  scale_fill_viridis_c(guide = "none") +
  theme_classic() +
  labs(x = "", y = "")

figure2 <- ggarrange(c, d,
                    labels = c("SSM (timbre)", "SSM (chroma)"),
                    ncol = 1, nrow = 2)

figure2
```


